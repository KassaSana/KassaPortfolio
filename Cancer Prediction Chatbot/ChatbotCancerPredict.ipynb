{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce7db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classifier cross val accuracy on predicting stage of pancreatic cancer :54.65621500559911\n",
      "MLP accuracy :47.45762711864407\n",
      "Best Parameters: {'activation': 'relu', 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'sgd'}\n",
      "Best Score: 0.7456493506493506\n",
      "Test Set Accuracy: 0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "import numpy as nump\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('pancreatic.csv')\n",
    "\n",
    "columns_to_drop = ['sample_id', 'patient_cohort', 'sample_origin', 'stage', 'benign_sample_diagnosis'] \n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.dropna(axis=1, inplace=True) #this removes the column with null values\n",
    "# df.dropna(axis=0, inplace=True) #this removes the row with null values\n",
    "df['sex'].replace({'M': 0, 'F': 1}, inplace=True)\n",
    "df\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "john = df_train.loc[:, [\"age\",\"sex\",\"creatinine\",\"LYVE1\",\"REG1B\",\"TFF1\"]]\n",
    "john\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "X_train, y_train, X_test, y_test = df_train.loc[:, [\"age\",\"sex\",\"creatinine\",\"LYVE1\",\"REG1B\",\"TFF1\"]], df_train.loc[:, [\"diagnosis\"]], df_test.loc[:, [\"age\",\"sex\",\"creatinine\",\"LYVE1\",\"REG1B\",\"TFF1\"]], df_test.loc[:, [\"diagnosis\"]]\n",
    "y_test\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracies = cross_val_score(model, X_train, y_train , cv = 5, scoring = \"accuracy\") #we can change the cv to split into as many chunks as we want\n",
    "nump.mean(accuracies)\n",
    "print(f\"MLP Classifier cross val accuracy on predicting stage of pancreatic cancer :{nump.mean(accuracies)*100}\")\n",
    "print(f\"MLP accuracy :{accuracy*100}\")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_excel('ovarian.xlsx')\n",
    "\n",
    "# Drop columns and handle missing values\n",
    "columns_to_drop = ['SUBJECT_ID']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.dropna(axis=1, inplace=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train, y_train = df_train.drop(columns=[\"TYPE\"]), df_train[\"TYPE\"]\n",
    "X_test, y_test = df_test.drop(columns=[\"TYPE\"]), df_test[\"TYPE\"]\n",
    "\n",
    "# Define the MLPClassifier model\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Define hyperparameters grid for tuning\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Predict on test set with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Set Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c459aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Random Forest accuracy :78.57142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.60      0.67         5\n",
      "           2       0.67      0.29      0.40         7\n",
      "           3       0.80      0.93      0.86        30\n",
      "\n",
      "    accuracy                           0.79        42\n",
      "   macro avg       0.74      0.61      0.64        42\n",
      "weighted avg       0.77      0.79      0.76        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "data = pd.read_csv('pancreatic.csv')\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['sample_id', 'patient_cohort', 'sample_origin', 'stage', 'benign_sample_diagnosis']\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Handle missing values if any\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Encoding age using LabelEncoder\n",
    "age_encoder = LabelEncoder()\n",
    "data['age_encoded'] = age_encoder.fit_transform(data['age'])\n",
    "\n",
    "# Encoding sex using OneHotEncoder\n",
    "if len(data) > 0:  # Check if there are still samples remaining\n",
    "    sex_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    sex_encoded = sex_encoder.fit_transform(data[['sex']])\n",
    "    data[['sex_encoded']] = sex_encoded\n",
    "\n",
    "    # Split data into features (X) and target variable (y)\n",
    "    X = data[['age_encoded', 'sex_encoded', 'plasma_CA19_9', 'creatinine', 'LYVE1', 'REG1B', 'TFF1', 'REG1A']]\n",
    "    y = data['diagnosis']\n",
    "\n",
    "    # Step 3: Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 4: Model Selection and Hyperparameter Tuning (Grid Search)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],  # Number of trees in random forest\n",
    "        'max_depth': [None, 10, 20, 30],  # Maximum number of levels in tree\n",
    "        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "        'min_samples_leaf': [1, 2, 4]  # Minimum number of samples required at each leaf node\n",
    "    }\n",
    "\n",
    "    RF_model = RandomForestClassifier()\n",
    "    grid_search = GridSearchCV(estimator=RF_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters found\n",
    "    print(\"Best parameters found:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    # Step 5: Model Training with Best Parameters\n",
    "    best_RF_model = grid_search.best_estimator_\n",
    "    best_RF_model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 6: Model Evaluation\n",
    "    y_pred = best_RF_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Random Forest accuracy :{accuracy*100}\")\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough data after preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5c0987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Cancer Prediction Chatbot!\n",
      "Please answer the following questions:\n",
      "Which form of cancer are you trying to predict: 1 (Ovarian) or 2 (Pancriatic)\n",
      "2\n",
      "Enter you age: 23\n",
      "Enter your sex: M or FM\n",
      "Enter your plasma_CA19_9 level: 1\n",
      "Enter your creatine level: 1\n",
      "Enter your LYVE1 level: 1\n",
      "Enter your REG1B level: 1\n",
      "Enter your TFF1 level: 1\n",
      "Enter your REG1A level: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cancer_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m:    \n\u001b[1;32m    104\u001b[0m     user_inputs \u001b[38;5;241m=\u001b[39m ask_pancriatic_question()\n\u001b[0;32m--> 105\u001b[0m     predicted_probability \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_pancriatic_cancer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Output prediction\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predicted_probability \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mpredict_pancriatic_cancer\u001b[0;34m(user_inputs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Reshape user inputs if needed based on your model input shape\u001b[39;00m\n\u001b[1;32m     86\u001b[0m user_inputs \u001b[38;5;241m=\u001b[39m user_inputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m predicted_probability \u001b[38;5;241m=\u001b[39m \u001b[43mbest_RF_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Use your pre-imported model to make predictions\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# predicted_probability = model.predict(user_inputs)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_probability\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:850\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    848\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 850\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    853\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 579\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "import os\n",
    "import numpy as nump\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "# Assuming you have imported your model as `model`\n",
    "# from sklearn or any other library\n",
    "# from sklearn import load_model\n",
    "# model = load_model('your_model.h5')\n",
    "\n",
    "# Sample data provided\n",
    "sample_data = [\n",
    "    [33, 0.07, 1.33, 3.81, 2.50, 99.7, 83.8, 0.02, 0.40, 4.08, 0, 0.98, 0.31, 5.89, 138.2, 0.90, 195, 4.55, 14.50, 276.1],\n",
    "    [50, 0.01, 0.20, 3.29, 2.44, 98.5, 47.0, 0.07, 1.60, 7.21, 1, 0.88, 0.24, 5.40, 142.5, 1.10, 284, 4.64, 12.10, 211.5],\n",
    "    [28, 0.02, 0.40, 4.26, 2.55, 104.5, 57.0, 0.07, 1.50, 4.70, 0, 0.91, 0.16, 3.50, 142.6, 1.09, 279, 4.44, 12.40, 298.1],\n",
    "    # Add more sample data as needed\n",
    "]\n",
    "\n",
    "# Load your model here\n",
    "\n",
    "# Function to ask questions and get user inputs\n",
    "def ask_ovarian_questions():\n",
    "    age = int(input(\"Enter your age: \"))\n",
    "    baso_count = float(input(\"Enter your BASO# count: \"))\n",
    "    baso_percentage = float(input(\"Enter your BASO%: \"))\n",
    "    bun = float(input(\"Enter your BUN: \"))\n",
    "    ca = float(input(\"Enter your Calcium level: \"))\n",
    "    cl = float(input(\"Enter your Chloride level: \"))\n",
    "    crea = float(input(\"Enter your Creatinine level: \"))\n",
    "    eo_count = float(input(\"Enter your EO# count: \"))\n",
    "    eo_percentage = float(input(\"Enter your EO%: \"))\n",
    "    glu = float(input(\"Enter your Glucose level: \"))\n",
    "    # Continue with more questions based on your dataset\n",
    "\n",
    "    # Return user inputs as a list\n",
    "    return [age, baso_count, baso_percentage, bun, ca, cl, crea, eo_count, eo_percentage, glu]\n",
    "\n",
    "#function to ask pancriatic questions\n",
    "def ask_pancriatic_question():\n",
    "    age_encoder = LabelEncoder()\n",
    "    sex_encoder = OneHotEncoder()\n",
    "    \n",
    "    #['age_encoded', 'sex_encoded', 'plasma_CA19_9', 'creatinine', 'LYVE1', 'REG1B', 'TFF1', 'REG1A']\n",
    "    age = int(input(\"Enter you age: \"))\n",
    "    age = np.array([age])  # Convert age to a 1-dimensional array\n",
    "    age = age_encoder.fit_transform(age)\n",
    "    sex = input(\"Enter your sex: M or F\")\n",
    "    sex = np.array([sex]).reshape(-1, 1)  # Reshape to a 2D array\n",
    "    sex_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    sex_encoded = sex_encoder.fit_transform(sex)\n",
    "    plasma_CA19_9 = float(input(\"Enter your plasma_CA19_9 level: \"))\n",
    "    creatine = float(input(\"Enter your creatine level: \"))\n",
    "    lyve1 = float(input(\"Enter your LYVE1 level: \"))\n",
    "    reg1b = float(input(\"Enter your REG1B level: \"))\n",
    "    tff1 = float(input(\"Enter your TFF1 level: \"))\n",
    "    reg1a = float(input(\"Enter your REG1A level: \"))\n",
    "    \n",
    "    return [age, sex_encoded, plasma_CA19_9, creatine, lyve1, reg1b, tff1, reg1a]\n",
    "# Function to predict cancer based on user inputs\n",
    "def predict_ovarian_cancer(user_inputs):\n",
    "    # Convert user inputs to numpy array\n",
    "    user_inputs = np.array(user_inputs)\n",
    "    # Reshape user inputs if needed based on your model input shape\n",
    "    user_inputs = user_inputs.reshape(1, -1)\n",
    "    predicted_probability = best_model.predict_proba(user_inputs)\n",
    "    # Use your pre-imported model to make predictions\n",
    "    # predicted_probability = model.predict(user_inputs)\n",
    "    return predicted_probability\n",
    "\n",
    "\n",
    "def predict_pancriatic_cancer(user_inputs):\n",
    "    # Convert user inputs to numpy array\n",
    "    user_inputs = np.array(user_inputs)\n",
    "    # Reshape user inputs if needed based on your model input shape\n",
    "    user_inputs = user_inputs.reshape(1, -1)\n",
    "    predicted_probability = best_RF_model.predict_proba(user_inputs)\n",
    "    # Use your pre-imported model to make predictions\n",
    "    # predicted_probability = model.predict(user_inputs)\n",
    "    return predicted_probability\n",
    "\n",
    "\n",
    "# Main function to run the chatbot\n",
    "def main():\n",
    "    print(\"Welcome to the Cancer Prediction Chatbot!\")\n",
    "    print(\"Please answer the following questions:\")\n",
    "    print(\"Which form of cancer are you trying to predict: 1 (Ovarian) or 2 (Pancriatic)\")\n",
    "    cancer_type = input()\n",
    "    if cancer_type == \"1\":\n",
    "        user_inputs = ask_ovarian_questions()\n",
    "        # Predict cancer based on user inputs\n",
    "        predicted_probability = predict_ovarian_cancer(user_inputs)\n",
    "    elif cancer_type == \"2\":    \n",
    "        user_inputs = ask_pancriatic_question()\n",
    "        predicted_probability = predict_pancriatic_cancer(user_inputs)\n",
    "    # Output prediction\n",
    "    if predicted_probability > 0.5:\n",
    "        print(\"Based on your inputs, there is a high probability that you have ovarian cancer.\")\n",
    "    else:\n",
    "        print(\"Based on your inputs, there is a low probability that you have ovarian cancer.\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8581695",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
